{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a252f3",
   "metadata": {},
   "source": [
    "***1. Обучить любую модель классификации на датасете IRIS до применения PCA (2 компоненты) и после него. Сравнить качество классификации по отложенной выборке.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fad48a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e370fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean(axis=0)) / x.std(axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "da80f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "target = iris.target\n",
    "X = X.astype(float)\n",
    "X = standard_scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "875f5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, \n",
    "                                                                    target, \n",
    "                                                                    test_size=0.3,\n",
    "                                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bf1bf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель леса из сотни деревьев (100 по умолчанию)\n",
    "model = RandomForestClassifier(max_depth = 4,\n",
    "                               max_features = None)\n",
    "# Обучаем на тренировочных данных\n",
    "model.fit(train_data, train_labels)\n",
    "\n",
    "\n",
    "train_predictions = model.predict(train_data)\n",
    "test_predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c6047bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тренировочных данных: 1.0\n",
      "accuracy на тестовых данных:0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Рассчитываем accuracy\n",
    "\n",
    "print(f\"accuracy на тренировочных данных: {accuracy_score(train_predictions, train_labels)}\\naccuracy на тестовых данных:{accuracy_score(test_predictions, test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943426d",
   "metadata": {},
   "source": [
    "Теперь примененяем PCA (2 компоненты) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f55fc8",
   "metadata": {},
   "source": [
    "Для реализации метода главных компонент нужно :\n",
    "- найти собственные значения матрицы $X^{T}X$;\n",
    "- отобрать $d$ максимальных;\n",
    "- составить матрицу $W^{T}$, столбцы которой будут являться собственными векторами, соответствующими отобранным собственным значениям, расположенным в порядке убывания;\n",
    "- получить новую матрицу \"объекты-признаки\", умножив исходную матрицу $X$ на матрицу весов $W$ :\n",
    "\n",
    "$$Z=XW.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "85c9c735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 4)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ddffb7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция между признаком 0 и 1: -0.8437233930683575\n",
      "Корреляция между признаком 0 и 2: -0.9458041967327759\n",
      "Корреляция между признаком 0 и 3: -0.9796474724420249\n",
      "Корреляция между признаком 1 и 2: 0.9715341143373748\n",
      "Корреляция между признаком 1 и 3: 0.9306523801434927\n",
      "Корреляция между признаком 2 и 3: 0.9876697877825587\n",
      "Корреляция между признаком 0 и целевой переменной: 0.7841502769135629\n",
      "Корреляция между признаком 1 и целевой переменной: -0.35725469728601256\n",
      "Корреляция между признаком 2 и целевой переменной: 0.9507340057925742\n",
      "Корреляция между признаком 3 и целевой переменной: 0.9572681043789399\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "indices = [0, 1, 2, 3]\n",
    "comb_of_indices = list(itertools.combinations(indices, 2)) \n",
    "for i in comb_of_indices:\n",
    "    print(f\"Корреляция между признаком {i[0]} и {i[1]}: {np.corrcoef(train_data[i[0]], train_data[i[1]])[0][1]}\")\n",
    "for i in indices:\n",
    "    print(f\"Корреляция между признаком {i} и целевой переменной: {np.corrcoef(train_data[:, i], train_labels)[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd63bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "62659d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([437.77467248, 137.10457072,  22.01353134,   3.10722546])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.52106591, -0.37741762, -0.71956635,  0.26128628],\n",
       "       [-0.26934744, -0.92329566,  0.24438178, -0.12350962],\n",
       "       [ 0.5804131 , -0.02449161,  0.14212637, -0.80144925],\n",
       "       [ 0.56485654, -0.06694199,  0.63427274,  0.52359713]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eig_val, eig_vecs = np.linalg.eig(X_red .T @ X_red)\n",
    "display(eig_val, eig_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9e1f8d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52106591, -0.37741762],\n",
       "       [-0.26934744, -0.92329566],\n",
       "       [ 0.5804131 , -0.02449161],\n",
       "       [ 0.56485654, -0.06694199]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = eig_vecs[:, :2]\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a6593e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72.96244541329992, 22.85076178670176, 3.668921889282871, 0.5178709107154739]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оцениваем объем потерянной информации\n",
    "\n",
    "eig_sum = sum(eig_val)\n",
    "[(i / eig_sum) * 100 for i in sorted(eig_val, reverse=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a25e05",
   "metadata": {},
   "source": [
    "Таким образом, наши большие векторы описывают 72.96 и 22.85%, а меньшие - 3.66 и 0.51%. Отбросив меньшие векторы и спроецировав данные на большие, мы потеряем меньше 5% информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f9f1d4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281, -0.4800266 ],\n",
       "       [-2.08096115,  0.67413356],\n",
       "       [-2.36422905,  0.34190802],\n",
       "       [-2.29938422,  0.59739451],\n",
       "       [-2.38984217, -0.64683538],\n",
       "       [-2.07563095, -1.48917752],\n",
       "       [-2.44402884, -0.0476442 ],\n",
       "       [-2.23284716, -0.22314807],\n",
       "       [-2.33464048,  1.11532768],\n",
       "       [-2.18432817,  0.46901356],\n",
       "       [-2.1663101 , -1.04369065],\n",
       "       [-2.32613087, -0.13307834],\n",
       "       [-2.2184509 ,  0.72867617],\n",
       "       [-2.6331007 ,  0.96150673],\n",
       "       [-2.1987406 , -1.86005711]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.dot(X_red, vec)\n",
    "Z[:15, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "61ab784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.37774672e+02, 2.77347589e-14],\n",
       "       [2.77347589e-14, 1.37104571e+02]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.T @ Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8b9ebcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26470281,  0.4800266 ],\n",
       "       [-2.08096115, -0.67413356],\n",
       "       [-2.36422905, -0.34190802],\n",
       "       [-2.29938422, -0.59739451],\n",
       "       [-2.38984217,  0.64683538],\n",
       "       [-2.07563095,  1.48917752],\n",
       "       [-2.44402884,  0.0476442 ],\n",
       "       [-2.23284716,  0.22314807],\n",
       "       [-2.33464048, -1.11532768],\n",
       "       [-2.18432817, -0.46901356],\n",
       "       [-2.1663101 ,  1.04369065],\n",
       "       [-2.32613087,  0.13307834],\n",
       "       [-2.2184509 , -0.72867617],\n",
       "       [-2.6331007 , -0.96150673],\n",
       "       [-2.1987406 ,  1.86005711]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X_red)\n",
    "X_reduced[:15, :]                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e83374d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "\n",
    "train_data_2, test_data_2, train_labels_2, test_labels_2 = train_test_split(Z, \n",
    "                                                                    target, \n",
    "                                                                    test_size=0.3,\n",
    "                                                                   random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b55c1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель леса из сотни деревьев (100 по умолчанию)\n",
    "model_2 = RandomForestClassifier(max_depth = 4,\n",
    "                               max_features = None)\n",
    "# Обучаем на новых тренировочных данных\n",
    "model_2.fit(train_data_2, train_labels_2)\n",
    "\n",
    "\n",
    "train_predictions_2 = model_2.predict(train_data_2)\n",
    "test_predictions_2 = model_2.predict(test_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a47aec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тренировочных данных: 0.9809523809523809\n",
      "accuracy на тестовых данных:0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Рассчитываем accuracy\n",
    "\n",
    "print(f\"accuracy на тренировочных данных: {accuracy_score(train_predictions_2, train_labels_2)}\\naccuracy на тестовых данных:{accuracy_score(test_predictions_2, test_labels_2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a069a5f",
   "metadata": {},
   "source": [
    "Результат обучения до PCA:\n",
    "     accuracy на тренировочных данных: 1.0,\n",
    "     accuracy на тестовых данных:0.9555555555555556\n",
    "\n",
    "Результат обучения после PCA:\n",
    "     accuracy на тренировочных данных: 0.9809523809523809,\n",
    "     accuracy на тестовых данных:0.9555555555555556\n",
    "     \n",
    "Качество классификации на тренировочных данных оказалось примерно одинаковым, на тестовых данных - абсолютно одинаковым."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b6e8a",
   "metadata": {},
   "source": [
    "****2.* Написать свою реализацию метода главных компонент с помощью сингулярного разложения с использованием функции numpy.linalg.svd()***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d6460",
   "metadata": {},
   "source": [
    "Для реализации понижения размерности методом главных компонент с помощью SVD нужно:\n",
    "- найти сингулярное разложение $X^TX$;\n",
    "- сформировать из столбцов матрицы $V$, соответствующих $d$ наибольшим сингулярным числам, матрицу весов $W$;\n",
    "- получить новую матрицу \"объекты-признаки\", умножив исходную матрицу $X$ на матрицу весов $W$:\n",
    "\n",
    "$$Z=XW.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "61a9579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[437.77467248 137.10457072  22.01353134   3.10722546]\n",
      "[[-0.52106591 -0.37741762  0.71956635  0.26128628]\n",
      " [ 0.26934744 -0.92329566 -0.24438178 -0.12350962]\n",
      " [-0.5804131  -0.02449161 -0.14212637 -0.80144925]\n",
      " [-0.56485654 -0.06694199 -0.63427274  0.52359713]]\n"
     ]
    }
   ],
   "source": [
    "u, d, v_t = np.linalg.svd(X_red .T @ X_red)\n",
    "v = v_t.T\n",
    "print(d)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "46e02233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52106591, -0.37741762],\n",
       "       [ 0.26934744, -0.92329566],\n",
       "       [-0.5804131 , -0.02449161],\n",
       "       [-0.56485654, -0.06694199]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = v[:, :2]\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1519f58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.26470281, -0.4800266 ],\n",
       "       [ 2.08096115,  0.67413356],\n",
       "       [ 2.36422905,  0.34190802],\n",
       "       [ 2.29938422,  0.59739451],\n",
       "       [ 2.38984217, -0.64683538],\n",
       "       [ 2.07563095, -1.48917752],\n",
       "       [ 2.44402884, -0.0476442 ],\n",
       "       [ 2.23284716, -0.22314807],\n",
       "       [ 2.33464048,  1.11532768],\n",
       "       [ 2.18432817,  0.46901356],\n",
       "       [ 2.1663101 , -1.04369065],\n",
       "       [ 2.32613087, -0.13307834],\n",
       "       [ 2.2184509 ,  0.72867617],\n",
       "       [ 2.6331007 ,  0.96150673],\n",
       "       [ 2.1987406 , -1.86005711]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_2 = np.dot(X_red, W)\n",
    "Z_2[:15, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6c901b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "\n",
    "train_data_3, test_data_3, train_labels_3, test_labels_3 = train_test_split(Z_2, \n",
    "                                                                    target, \n",
    "                                                                    test_size=0.3,\n",
    "                                                                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6aa4846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель леса из сотни деревьев (100 по умолчанию)\n",
    "model_3 = RandomForestClassifier(max_depth = 4,\n",
    "                               max_features = None)\n",
    "# Обучаем на новых тренировочных данных\n",
    "model_3.fit(train_data_3, train_labels_3)\n",
    "\n",
    "\n",
    "train_predictions_3 = model_3.predict(train_data_3)\n",
    "test_predictions_3 = model_3.predict(test_data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "345cb91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тренировочных данных: 0.9904761904761905\n",
      "accuracy на тестовых данных:0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Рассчитываем accuracy\n",
    "\n",
    "print(f\"accuracy на тренировочных данных: {accuracy_score(train_predictions_3, train_labels_3)}\\naccuracy на тестовых данных:{accuracy_score(test_predictions_3, test_labels_3)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
